{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and configure the sentiment analyzer.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "TWEETS_DATABASE_FILENAME = 'tweets_data.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets...\n",
      "314104 tweets already have sentiment data\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(TWEETS_DATABASE_FILENAME)\n",
    "\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    print('Getting tweets...')\n",
    "    completed_tweets_count = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "            COUNT(id)\n",
    "        FROM\n",
    "            tweets\n",
    "        WHERE\n",
    "            sentiment IS NOT NULL\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    print(completed_tweets_count, 'tweets already have sentiment data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets...\n",
      "updated tweet 10000\n",
      "updated tweet 20000\n",
      "updated tweet 30000\n",
      "updated tweet 40000\n",
      "updated tweet 50000\n",
      "Getting tweets...\n",
      "updated tweet 60000\n",
      "updated tweet 70000\n",
      "updated tweet 80000\n",
      "updated tweet 90000\n",
      "updated tweet 100000\n",
      "Getting tweets...\n",
      "updated tweet 110000\n",
      "updated tweet 120000\n",
      "updated tweet 130000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5f60fccd4e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mgenerate_and_insert_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rollback'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5f60fccd4e58>\u001b[0m in \u001b[0;36mgenerate_and_insert_tweets\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtweet_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msentiment_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         values_to_commit.append(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_but_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mvalence_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_valence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalence_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36mscore_valence\u001b[0;34m(self, sentiments, text)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0msum_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# compute and add emphasis from punctuation in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mpunct_emph_amplifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_punctuation_emphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msum_s\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0msum_s\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpunct_emph_amplifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36m_punctuation_emphasis\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_punctuation_emphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# add emphasis from exclamation points and question marks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mep_amplifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amplify_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mqm_amplifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amplify_qm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mpunct_emph_amplifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep_amplifier\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mqm_amplifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py\u001b[0m in \u001b[0;36m_amplify_ep\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_amplify_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# check for added emphasis resulting from exclamation points (up to 4 of them)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mep_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mep_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mep_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import json\n",
    "\n",
    "conn = sqlite3.connect(TWEETS_DATABASE_FILENAME)\n",
    "conn.isolation_level = \"DEFERRED\"\n",
    "\n",
    "has_null_sentiment_tweets = True\n",
    "\n",
    "completed_batches_count = 0\n",
    "\n",
    "insert_batch_size = 10000\n",
    "\n",
    "\n",
    "def insert_batch_to_db(values_to_commit):\n",
    "    \"\"\"\n",
    "    Batch insert tweet data into the database.\n",
    "    \"\"\"\n",
    "    sql = \"\"\"\n",
    "        INSERT OR REPLACE INTO\n",
    "            tweets (id, sentiment, data) \n",
    "        VALUES (\n",
    "            ?, \n",
    "            ?,\n",
    "            (\n",
    "                SELECT\n",
    "                    data\n",
    "                FROM\n",
    "                    tweets\n",
    "                WHERE\n",
    "                    id = ?\n",
    "            )\n",
    "        );\n",
    "    \"\"\"\n",
    "    cur.executemany(sql, values_to_commit)\n",
    "\n",
    "\n",
    "def generate_and_insert_tweets(results):\n",
    "    \"\"\"\n",
    "    Generates sentiment data and updates the database with the new data, given SQL results.\n",
    "    \"\"\"\n",
    "    values_to_commit = []\n",
    "    for index, result in enumerate(results):\n",
    "        tweet_text = result[0]\n",
    "        tweet_id = result[1]\n",
    "\n",
    "        sentiment_scores = analyser.polarity_scores(tweet_text)\n",
    "\n",
    "        values_to_commit.append(\n",
    "            [tweet_id, json.dumps(sentiment_scores), tweet_id])\n",
    "\n",
    "        if (index + 1) % insert_batch_size == 0:\n",
    "            insert_batch_to_db(values_to_commit)\n",
    "\n",
    "            print('updated tweet',\n",
    "                  (completed_batches_count * 50000) + index + 1)\n",
    "            values_to_commit = []  # Reset to empty\n",
    "\n",
    "\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    while has_null_sentiment_tweets:\n",
    "        print('Getting tweets...')\n",
    "\n",
    "        # Query sentiment data in batches of 50k\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                json_extract(data, '$.text'), id\n",
    "            FROM\n",
    "                tweets\n",
    "            WHERE\n",
    "                sentiment IS NULL\n",
    "            LIMIT 50000\n",
    "        \"\"\")\n",
    "        results = cur.fetchall()\n",
    "\n",
    "        # Case: all tweets already have sentiment data\n",
    "        if len(results) == 0:\n",
    "            has_null_sentiment_tweets = False\n",
    "            break\n",
    "\n",
    "        values_to_commit = []\n",
    "\n",
    "        cur.execute(\"begin\")\n",
    "        try:\n",
    "            generate_and_insert_tweets(results)\n",
    "        except sqlite3.Error as e:\n",
    "            cur.execute('rollback')\n",
    "        finally:\n",
    "            conn.execute('commit')\n",
    "\n",
    "        completed_batches_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting count...\n",
      "629111 database record(s) have sentiment information\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(TWEETS_DATABASE_FILENAME)\n",
    "\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    print('Getting count...')\n",
    "    cur.execute(\"SELECT COUNT(id) FROM tweets WHERE sentiment NOT NULL\")\n",
    "    print(cur.fetchone()[0], 'database record(s) have sentiment information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
